{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c5a7fc-342c-4f24-80f4-d4ff0e38510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom mpl_toolkits.mplot3d import Axes3D\\n# import joblib\\nimport pickle\\n\\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\\n\\n# =============================================================================\\n# Paso 1: Registrar información de los mejores modelos en CSV\\n# =============================================================================\\nbest_model_info = pd.DataFrame({\\n    \\'Output\\': [\\'p1::W\\', \\'p4::GFF\\', \\'p5::BSP_T\\', \\'p6::BSP_n\\', \\'p7::BSP_Mu\\', \\'p8::MSP_n\\', \\'p9::UWP_Mu\\'],\\n    \\'ModelType\\': [\\'PLS\\', \\'LR\\', \\'GPR\\', \\'SVR\\', \\'GPR\\', \\'PLS\\', \\'SVR\\'],\\n    \\'CoP\\': [0.95, 0.92, 0.94, 0.90, 0.96, 0.93, 0.91],\\n    \\'Hyperparameters\\': [\\'n_components=9\\', \\'fit_intercept=False\\', \\'length_scale=2.52, noise=0.0388\\',\\n                        \\'C=10, epsilon=0.1\\', \\'length_scale=3.74, noise=0.00211\\', \\'n_components=9\\', \\'C=1, epsilon=0.5\\']\\n})\\n#best_model_info.to_csv(\\'best_models.csv\\', index=False)\\nprint(\"Información de los mejores modelos guardada en \\'best_models.csv\\'.\")\\n\\n# =============================================================================\\n# Paso 2: Generar 10,000 nuevos motores a partir de los rangos de entrada\\n# =============================================================================\\n# Se carga el dataset original para obtener los límites de las variables de entrada\\ndata_file = \"design_DB_preprocessed_200_Optimizado.csv\"  # Ajustar ruta según corresponda.\\ndf = pd.read_csv(data_file)\\n\\n# Se consideran las variables de entrada que comienzan con \\'x\\' y \\'m\\'\\ninput_cols = [col for col in df.columns if col.startswith(\\'x\\')] + [col for col in df.columns if col.startswith(\\'m\\')]\\nX_min = df[input_cols].min()\\nX_max = df[input_cols].max()\\n\\nn_samples = 10000\\n# Generar nuevos motores de forma uniforme dentro de los rangos observados\\nX_new = pd.DataFrame({col: np.random.uniform(low=X_min[col], high=X_max[col], size=n_samples) \\n                      for col in input_cols})\\n\\n# =============================================================================\\n# Paso 3: Preprocesar los nuevos datos con el mismo escalador usado en entrenamiento\\n# =============================================================================\\n# Definir la ruta del archivo del ensemble (se asume que figure_path ya está definido)\\nensemble_file = os.path.join(model_path, \"best_model_ensemble.pkl\")\\n# Cargar el modelo ensemble utilizando pickle\\nwith open(ensemble_file, \"rb\") as f:\\n    loaded_ensemble = pickle.load(f)\\nprint(\"Modelo ensemble cargado correctamente desde:\", ensemble_file)\\n\\n\\n# Escalado de datos\\nscaler_X = StandardScaler()\\nX_scaled = scaler_X.fit_transform(X)\\nscaler_Y = StandardScaler()\\nY_scaled = scaler_Y.fit_transform(Y)\\n\\n# Obtener las predicciones del ensemble para los datos escalados (por ejemplo, el conjunto completo)\\npreds_ensemble = loaded_ensemble.predict(X_scaled_df)\\n\\n# Lista de variables de salida (usando el DataFrame escalado de Y)\\noutput_vars = Y_scaled_df.columns.tolist()\\n\\n# =============================================================================\\n# Paso 4: Predecir las variables de salida usando los modelos subrogados óptimos\\n# =============================================================================\\n# Se asume que los modelos subrogados para cada variable de salida se guardaron\\n# en archivos llamados \"surrogate_pX.pkl\" dentro de la carpeta \"Modelos_subrogados\"\\noutput_vars = [\\'p1::W\\', \\'p4::GFF\\', \\'p5::BSP_T\\', \\'p6::BSP_n\\', \\'p7::BSP_Mu\\', \\'p8::MSP_n\\', \\'p9::UWP_Mu\\']\\nsurrogate_models = {}\\npredictions = {}\\n\\nfor output in output_vars:\\n    model_path = os.path.join(\"Modelos_subrogados\", f\"surrogate_{output}.pkl\")\\n    # Cargar el modelo subrogado óptimo para la salida \\'output\\'\\n    surrogate_models[output] = joblib.load(model_path)\\n    # Predecir la salida para los nuevos datos escalados\\n    predictions[output] = surrogate_models[output].predict(X_new_scaled)\\n\\n# Combinar las predicciones en un DataFrame\\ndf_predictions = pd.DataFrame(predictions)\\n\\n# Combinar las variables de entrada originales y las salidas predichas\\nmotors = pd.concat([X_new, df_predictions], axis=1)\\nmotors.to_csv(\"generated_motors.csv\", index=False)\\nprint(\"Base de datos de 10,000 motores guardada en \\'generated_motors.csv\\'.\")\\n\\n# =============================================================================\\n# Paso 5: Filtrar motores válidos según constraints definidos\\n# =============================================================================\\ndef is_valid_motor(row):\\n    # Ejemplo de constraints (ajustar según lo indicado en el paper)\\n    # Se desea que:\\n    # - p1::W esté entre 0.5 y 0.7\\n    # - p7::BSP_Mu esté entre 85 y 90\\n    # - p9::UWP_Mu esté entre 88 y 92\\n    if (0.5 <= row[\\'p1::W\\'] <= 0.7) and (85 <= row[\\'p7::BSP_Mu\\'] <= 90) and (88 <= row[\\'p9::UWP_Mu\\'] <= 92):\\n        return True\\n    return False\\n\\nmotors[\\'Valid\\'] = motors.apply(is_valid_motor, axis=1)\\nvalid_motors = motors[motors[\\'Valid\\']]\\nprint(f\"Número de motores válidos: {len(valid_motors)}\")\\n\\n# =============================================================================\\n# Paso 6: Calcular y representar la frontera de Pareto\\n# =============================================================================\\n# Objetivos: minimizar p1::W, maximizar p7::BSP_Mu y p9::UWP_Mu\\ndef compute_pareto_front(df, objectives):\\n    is_dominated = np.zeros(len(df), dtype=bool)\\n    for i in range(len(df)):\\n        for j in range(len(df)):\\n            if i == j:\\n                continue\\n            dominates = True\\n            for obj, sense in objectives.items():\\n                if sense == \\'min\\':\\n                    if df.iloc[j][obj] > df.iloc[i][obj]:\\n                        dominates = False\\n                        break\\n                elif sense == \\'max\\':\\n                    if df.iloc[j][obj] < df.iloc[i][obj]:\\n                        dominates = False\\n                        break\\n            if dominates:\\n                is_dominated[i] = True\\n                break\\n    frontier = df[~is_dominated]\\n    return frontier\\n\\nobjectives = {\\'p1::W\\': \\'min\\', \\'p7::BSP_Mu\\': \\'max\\', \\'p9::UWP_Mu\\': \\'max\\'}\\nvalid_motors_reset = valid_motors.reset_index(drop=True)\\npareto_motors = compute_pareto_front(valid_motors_reset, objectives)\\nprint(f\"Número de motores en la frontera de Pareto: {len(pareto_motors)}\")\\n\\n# Representación 3D de la frontera de Pareto\\nfig = plt.figure()\\nax = fig.add_subplot(111, projection=\\'3d\\')\\nax.scatter(valid_motors[\\'p1::W\\'], valid_motors[\\'p7::BSP_Mu\\'], valid_motors[\\'p9::UWP_Mu\\'], \\n           c=\\'blue\\', label=\\'Válidos\\', alpha=0.5)\\nax.scatter(motors[~motors[\\'Valid\\']][\\'p1::W\\'], motors[~motors[\\'Valid\\']][\\'p7::BSP_Mu\\'], motors[~motors[\\'Valid\\']][\\'p9::UWP_Mu\\'], \\n           c=\\'red\\', label=\\'No válidos\\', alpha=0.5)\\nax.scatter(pareto_motors[\\'p1::W\\'], pareto_motors[\\'p7::BSP_Mu\\'], pareto_motors[\\'p9::UWP_Mu\\'], \\n           c=\\'green\\', label=\\'Frontera Pareto\\', s=100, marker=\\'D\\')\\nax.set_xlabel(\\'p1::W\\')\\nax.set_ylabel(\\'p7::BSP_Mu\\')\\nax.set_zlabel(\\'p9::UWP_Mu\\')\\nax.legend()\\nplt.title(\\'Frontera de Pareto de diseños de motores\\')\\nplt.savefig(\"pareto_frontier.png\", dpi=300)\\nplt.show()\\n\\n# =============================================================================\\n# Paso 7: Seleccionar el motor válido óptimo\\n# =============================================================================\\n# Se normalizan los objetivos y se define un score compuesto\\nvalid_motors_comp = valid_motors.copy()\\nfor col, sense in [(\\'p1::W\\', \\'min\\'), (\\'p7::BSP_Mu\\', \\'max\\'), (\\'p9::UWP_Mu\\', \\'max\\')]:\\n    col_min = valid_motors_comp[col].min()\\n    col_max = valid_motors_comp[col].max()\\n    if sense == \\'min\\':\\n        valid_motors_comp[col + \\'_norm\\'] = 1 - (valid_motors_comp[col] - col_min) / (col_max - col_min)\\n    else:\\n        valid_motors_comp[col + \\'_norm\\'] = (valid_motors_comp[col] - col_min) / (col_max - col_min)\\n\\nvalid_motors_comp[\\'composite_score\\'] = (valid_motors_comp[\\'p1::W_norm\\'] +\\n                                          valid_motors_comp[\\'p7::BSP_Mu_norm\\'] +\\n                                          valid_motors_comp[\\'p9::UWP_Mu_norm\\'])\\noptimal_motor = valid_motors_comp.loc[valid_motors_comp[\\'composite_score\\'].idxmax()]\\nprint(\"Motor válido óptimo (según score compuesto):\")\\nprint(optimal_motor)\\n\\noptimal_motor.to_frame().T.to_csv(\"optimal_motor.csv\", index=False)\\nprint(\"El motor óptimo se ha guardado en \\'optimal_motor.csv\\'.\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 1: Registrar información de los mejores modelos en CSV\n",
    "# =============================================================================\n",
    "best_model_info = pd.DataFrame({\n",
    "    'Output': ['p1::W', 'p4::GFF', 'p5::BSP_T', 'p6::BSP_n', 'p7::BSP_Mu', 'p8::MSP_n', 'p9::UWP_Mu'],\n",
    "    'ModelType': ['PLS', 'LR', 'GPR', 'SVR', 'GPR', 'PLS', 'SVR'],\n",
    "    'CoP': [0.95, 0.92, 0.94, 0.90, 0.96, 0.93, 0.91],\n",
    "    'Hyperparameters': ['n_components=9', 'fit_intercept=False', 'length_scale=2.52, noise=0.0388',\n",
    "                        'C=10, epsilon=0.1', 'length_scale=3.74, noise=0.00211', 'n_components=9', 'C=1, epsilon=0.5']\n",
    "})\n",
    "#best_model_info.to_csv('best_models.csv', index=False)\n",
    "print(\"Información de los mejores modelos guardada en 'best_models.csv'.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 2: Generar 10,000 nuevos motores a partir de los rangos de entrada\n",
    "# =============================================================================\n",
    "# Se carga el dataset original para obtener los límites de las variables de entrada\n",
    "data_file = \"design_DB_preprocessed_200_Optimizado.csv\"  # Ajustar ruta según corresponda.\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Se consideran las variables de entrada que comienzan con 'x' y 'm'\n",
    "input_cols = [col for col in df.columns if col.startswith('x')] + [col for col in df.columns if col.startswith('m')]\n",
    "X_min = df[input_cols].min()\n",
    "X_max = df[input_cols].max()\n",
    "\n",
    "n_samples = 10000\n",
    "# Generar nuevos motores de forma uniforme dentro de los rangos observados\n",
    "X_new = pd.DataFrame({col: np.random.uniform(low=X_min[col], high=X_max[col], size=n_samples) \n",
    "                      for col in input_cols})\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 3: Preprocesar los nuevos datos con el mismo escalador usado en entrenamiento\n",
    "# =============================================================================\n",
    "# Definir la ruta del archivo del ensemble (se asume que figure_path ya está definido)\n",
    "ensemble_file = os.path.join(model_path, \"best_model_ensemble.pkl\")\n",
    "# Cargar el modelo ensemble utilizando pickle\n",
    "with open(ensemble_file, \"rb\") as f:\n",
    "    loaded_ensemble = pickle.load(f)\n",
    "print(\"Modelo ensemble cargado correctamente desde:\", ensemble_file)\n",
    "\n",
    "\n",
    "# Escalado de datos\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y)\n",
    "\n",
    "# Obtener las predicciones del ensemble para los datos escalados (por ejemplo, el conjunto completo)\n",
    "preds_ensemble = loaded_ensemble.predict(X_scaled_df)\n",
    "\n",
    "# Lista de variables de salida (usando el DataFrame escalado de Y)\n",
    "output_vars = Y_scaled_df.columns.tolist()\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 4: Predecir las variables de salida usando los modelos subrogados óptimos\n",
    "# =============================================================================\n",
    "# Se asume que los modelos subrogados para cada variable de salida se guardaron\n",
    "# en archivos llamados \"surrogate_pX.pkl\" dentro de la carpeta \"Modelos_subrogados\"\n",
    "output_vars = ['p1::W', 'p4::GFF', 'p5::BSP_T', 'p6::BSP_n', 'p7::BSP_Mu', 'p8::MSP_n', 'p9::UWP_Mu']\n",
    "surrogate_models = {}\n",
    "predictions = {}\n",
    "\n",
    "for output in output_vars:\n",
    "    model_path = os.path.join(\"Modelos_subrogados\", f\"surrogate_{output}.pkl\")\n",
    "    # Cargar el modelo subrogado óptimo para la salida 'output'\n",
    "    surrogate_models[output] = joblib.load(model_path)\n",
    "    # Predecir la salida para los nuevos datos escalados\n",
    "    predictions[output] = surrogate_models[output].predict(X_new_scaled)\n",
    "\n",
    "# Combinar las predicciones en un DataFrame\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Combinar las variables de entrada originales y las salidas predichas\n",
    "motors = pd.concat([X_new, df_predictions], axis=1)\n",
    "motors.to_csv(\"generated_motors.csv\", index=False)\n",
    "print(\"Base de datos de 10,000 motores guardada en 'generated_motors.csv'.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 5: Filtrar motores válidos según constraints definidos\n",
    "# =============================================================================\n",
    "def is_valid_motor(row):\n",
    "    # Ejemplo de constraints (ajustar según lo indicado en el paper)\n",
    "    # Se desea que:\n",
    "    # - p1::W esté entre 0.5 y 0.7\n",
    "    # - p7::BSP_Mu esté entre 85 y 90\n",
    "    # - p9::UWP_Mu esté entre 88 y 92\n",
    "    if (0.5 <= row['p1::W'] <= 0.7) and (85 <= row['p7::BSP_Mu'] <= 90) and (88 <= row['p9::UWP_Mu'] <= 92):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "motors['Valid'] = motors.apply(is_valid_motor, axis=1)\n",
    "valid_motors = motors[motors['Valid']]\n",
    "print(f\"Número de motores válidos: {len(valid_motors)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 6: Calcular y representar la frontera de Pareto\n",
    "# =============================================================================\n",
    "# Objetivos: minimizar p1::W, maximizar p7::BSP_Mu y p9::UWP_Mu\n",
    "def compute_pareto_front(df, objectives):\n",
    "    is_dominated = np.zeros(len(df), dtype=bool)\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            dominates = True\n",
    "            for obj, sense in objectives.items():\n",
    "                if sense == 'min':\n",
    "                    if df.iloc[j][obj] > df.iloc[i][obj]:\n",
    "                        dominates = False\n",
    "                        break\n",
    "                elif sense == 'max':\n",
    "                    if df.iloc[j][obj] < df.iloc[i][obj]:\n",
    "                        dominates = False\n",
    "                        break\n",
    "            if dominates:\n",
    "                is_dominated[i] = True\n",
    "                break\n",
    "    frontier = df[~is_dominated]\n",
    "    return frontier\n",
    "\n",
    "objectives = {'p1::W': 'min', 'p7::BSP_Mu': 'max', 'p9::UWP_Mu': 'max'}\n",
    "valid_motors_reset = valid_motors.reset_index(drop=True)\n",
    "pareto_motors = compute_pareto_front(valid_motors_reset, objectives)\n",
    "print(f\"Número de motores en la frontera de Pareto: {len(pareto_motors)}\")\n",
    "\n",
    "# Representación 3D de la frontera de Pareto\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(valid_motors['p1::W'], valid_motors['p7::BSP_Mu'], valid_motors['p9::UWP_Mu'], \n",
    "           c='blue', label='Válidos', alpha=0.5)\n",
    "ax.scatter(motors[~motors['Valid']]['p1::W'], motors[~motors['Valid']]['p7::BSP_Mu'], motors[~motors['Valid']]['p9::UWP_Mu'], \n",
    "           c='red', label='No válidos', alpha=0.5)\n",
    "ax.scatter(pareto_motors['p1::W'], pareto_motors['p7::BSP_Mu'], pareto_motors['p9::UWP_Mu'], \n",
    "           c='green', label='Frontera Pareto', s=100, marker='D')\n",
    "ax.set_xlabel('p1::W')\n",
    "ax.set_ylabel('p7::BSP_Mu')\n",
    "ax.set_zlabel('p9::UWP_Mu')\n",
    "ax.legend()\n",
    "plt.title('Frontera de Pareto de diseños de motores')\n",
    "plt.savefig(\"pareto_frontier.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Paso 7: Seleccionar el motor válido óptimo\n",
    "# =============================================================================\n",
    "# Se normalizan los objetivos y se define un score compuesto\n",
    "valid_motors_comp = valid_motors.copy()\n",
    "for col, sense in [('p1::W', 'min'), ('p7::BSP_Mu', 'max'), ('p9::UWP_Mu', 'max')]:\n",
    "    col_min = valid_motors_comp[col].min()\n",
    "    col_max = valid_motors_comp[col].max()\n",
    "    if sense == 'min':\n",
    "        valid_motors_comp[col + '_norm'] = 1 - (valid_motors_comp[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        valid_motors_comp[col + '_norm'] = (valid_motors_comp[col] - col_min) / (col_max - col_min)\n",
    "\n",
    "valid_motors_comp['composite_score'] = (valid_motors_comp['p1::W_norm'] +\n",
    "                                          valid_motors_comp['p7::BSP_Mu_norm'] +\n",
    "                                          valid_motors_comp['p9::UWP_Mu_norm'])\n",
    "optimal_motor = valid_motors_comp.loc[valid_motors_comp['composite_score'].idxmax()]\n",
    "print(\"Motor válido óptimo (según score compuesto):\")\n",
    "print(optimal_motor)\n",
    "\n",
    "optimal_motor.to_frame().T.to_csv(\"optimal_motor.csv\", index=False)\n",
    "print(\"El motor óptimo se ha guardado en 'optimal_motor.csv'.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c787112-1a7f-4b43-864f-39f6ff546212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías necesarias\n",
    "import os\n",
    "import re  # Import the regular expression module\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715705d2-9877-4d41-8fed-3feaac4559e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de datos: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\4.DBG\\DB_MOP\\design_DB_preprocessed_400_Optimizado.csv\n",
      "Ruta de figuras: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\4.DBG\\Figuras_MOP\\400_MOT_Optimizado\n",
      "C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\4.DBG\\Modelos_MOP\\400_MOT_Optimizado\n",
      "Ruta de modelos: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\4.DBG\\Modelos_MOP\\400_MOT_Optimizado\n",
      "Archivo cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 1: Definir rutas, cargar datos y configurar directorios\n",
    "# =============================================================================\n",
    "base_path = os.getcwd()  # Se asume que el notebook se ejecuta desde la carpeta 'MOP'\n",
    "db_path = os.path.join(base_path, \"DB_MOP\")\n",
    "fig_path = os.path.join(base_path, \"Figuras_MOP\")\n",
    "model_path = os.path.join(base_path, \"Modelos_MOP\")\n",
    "\n",
    "# Ruta al archivo de la base de datos\n",
    "data_file = os.path.join(db_path, \"design_DB_preprocessed_400_Optimizado.csv\")\n",
    "print(\"Ruta de datos:\", data_file)\n",
    "\n",
    "# Ruta donde se guardarán las figuras\n",
    "figure_path = os.path.join(fig_path, \"400_MOT_Optimizado\")\n",
    "if not os.path.exists(figure_path):\n",
    "    os.makedirs(figure_path)\n",
    "print(\"Ruta de figuras:\", figure_path)\n",
    "\n",
    "# Ruta al archivo de los modelos\n",
    "model_path = os.path.join(model_path, \"400_MOT_Optimizado\")\n",
    "print(model_path)\n",
    "print(\"Ruta de modelos:\", model_path)\n",
    "\n",
    "# Lectura del archivo CSV\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(\"Archivo cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Archivo no encontrado. Revisa la ruta del archivo.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: Problema al analizar el archivo CSV. Revisa el formato del archivo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "# Función para limpiar nombres de archivo inválidos\n",
    "def clean_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3705abb2-bb74-4894-b7a6-8d046e44ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 2: Preprocesar datos: separar columnas en X, M, P y convertir a numérico\n",
    "# =============================================================================\n",
    "X_cols = [col for col in df.columns if col.startswith('x')]\n",
    "M_cols = [col for col in df.columns if col.startswith('m')]\n",
    "P_cols = [col for col in df.columns if col.startswith('p')]\n",
    "\n",
    "X = df[X_cols].copy()\n",
    "M = df[M_cols].copy()\n",
    "P = df[P_cols].copy()\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "for col in M.columns:\n",
    "    M[col] = pd.to_numeric(M[col], errors='coerce')\n",
    "for col in P.columns:\n",
    "    P[col] = pd.to_numeric(P[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13aa92cd-5e03-486f-a57f-16f9acd1afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables de entrada: ['x1::OSD', 'x2::Dint', 'x3::L', 'x4::tm', 'x5::hs2', 'x6::wt', 'x7::Nt', 'x8::Nh', 'm1::Drot', 'm2::Dsh', 'm3::he', 'm4::Rmag', 'm5::Rs', 'm6::GFF']\n",
      "Variables de salida: ['p1::W', 'p4::GFF', 'p5::BSP_T', 'p6::BSP_n', 'p7::BSP_Mu', 'p8::MSP_n', 'p9::UWP_Mu']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 3: Seleccionar variables de entrada y salida\n",
    "# =============================================================================\n",
    "# Las variables de salida se toman de P; se eliminan 'p2::Tnom' y 'p3::nnom' si existen.\n",
    "outputs = [col for col in P.columns]\n",
    "if 'p2::Tnom' in outputs:\n",
    "    outputs.remove('p2::Tnom')\n",
    "if 'p3::nnom' in outputs:\n",
    "    outputs.remove('p3::nnom')\n",
    "\n",
    "# Las variables de entrada se obtienen concatenando X y M.\n",
    "X_M = pd.concat([X, M], axis=1)\n",
    "features = list(X_M.columns)\n",
    "print(\"Variables de entrada:\", features)\n",
    "print(\"Variables de salida:\", outputs)\n",
    "\n",
    "# Redefinir X y Y usando los nombres de columnas seleccionados\n",
    "X = df[features]\n",
    "Y = df[outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb96662-190e-4dee-bc89-9f9f76f39b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 4: Generar 10,000 nuevos motores a partir de los rangos de entrada\n",
    "# =============================================================================\n",
    "# Guardamos los valores máximos y mínimos\n",
    "X_min = df[features].min()\n",
    "X_max = df[features].max()\n",
    "\n",
    "n_samples = 10000\n",
    "# Generar nuevos motores de forma uniforme dentro de los rangos observados\n",
    "X_new = pd.DataFrame({col: np.random.uniform(low=X_min[col], high=X_max[col], size=n_samples) \n",
    "                      for col in features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a38bca44-aa0e-4c57-8724-9e8179d72b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 5: Escalado de datos\n",
    "# =============================================================================\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_new)\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y)\n",
    "\n",
    "\n",
    "# Crear DataFrames escalados completos (para reentrenamiento final y predicciones)\n",
    "X_scaled_df = pd.DataFrame(scaler_X.transform(X_new), columns=X_new.columns, index=X_new.index)\n",
    "Y_scaled_df = pd.DataFrame(scaler_Y.transform(Y), columns=Y.columns, index=Y.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca9abf8-c1f5-4e4e-8161-131afceb7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Definir una clase que encapsule el ensemble de los mejores modelos\n",
    "# -----------------------------------------------------------------------------\n",
    "class BestModelEnsemble:\n",
    "    def __init__(self, model_dict, outputs):\n",
    "        \"\"\"\n",
    "        model_dict: Diccionario que mapea cada variable de salida a una tupla (modelo, índice)\n",
    "                    donde 'modelo' es el mejor modelo para esa salida y 'índice' es la posición\n",
    "                    de esa salida en el vector de predicción que produce ese modelo.\n",
    "        outputs: Lista de nombres de variables de salida, en el orden deseado.\n",
    "        \"\"\"\n",
    "        self.model_dict = model_dict\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Realiza la predicción para cada variable de salida usando el modelo asignado.\n",
    "        Se espera que cada modelo tenga un método predict que devuelva un array de\n",
    "        dimensiones (n_samples, n_outputs_model). Si el modelo es univariable, se asume\n",
    "        que devuelve un array 1D.\n",
    "        \n",
    "        :param X: Datos de entrada (array o DataFrame) con la forma (n_samples, n_features).\n",
    "        :return: Array con la predicción para todas las variables de salida, forma (n_samples, n_outputs).\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_outputs = len(self.outputs)\n",
    "        preds = np.zeros((n_samples, n_outputs))\n",
    "        \n",
    "        # Iterar sobre cada variable de salida\n",
    "        for output in self.outputs:\n",
    "            model, idx = self.model_dict[output]\n",
    "            model_pred = model.predict(X)\n",
    "            # Si el modelo es univariable, model_pred es 1D; de lo contrario, es 2D\n",
    "            if model_pred.ndim == 1:\n",
    "                preds[:, self.outputs.index(output)] = model_pred\n",
    "            else:\n",
    "                preds[:, self.outputs.index(output)] = model_pred[:, idx]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f887c2-189b-47c0-9294-6e2f88e93492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ensemble cargado correctamente desde: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\4.DBG\\Modelos_MOP\\400_MOT_Optimizado\\best_model_ensemble.pkl\n",
      "      p1::W        p4::GFF  p5::BSP_T  p6::BSP_n  p7::BSP_Mu  p8::MSP_n  \\\n",
      "0  0.658658  126463.385768   0.860282  -0.447577    1.015153   0.598805   \n",
      "1 -1.448138   -6034.137718  -0.918992   0.743497    0.098881   0.977144   \n",
      "2  1.282805   78826.701591   2.918427  -1.015112   -0.413248  -1.099346   \n",
      "3  0.955392  -13743.934211   1.341643  -0.807188    0.111320  -0.923332   \n",
      "4  0.650779   -3976.764288   0.709440  -0.857263   -0.266586  -1.195770   \n",
      "\n",
      "   p9::UWP_Mu  \n",
      "0    0.524473  \n",
      "1   -1.245760  \n",
      "2   -0.417232  \n",
      "3    1.169618  \n",
      "4    0.204383  \n",
      "     x1::OSD   x2::Dint      x3::L    x4::tm    x5::hs2    x6::wt     x7::Nt  \\\n",
      "0  47.610895  40.195027  34.329864  2.501234   8.041717  3.094406   6.578554   \n",
      "1  56.905775  25.878791  12.021049  2.647881  11.504395  3.279891  18.854601   \n",
      "2  54.983807  39.015605  35.142434  2.726291   6.754409  2.282239  20.064783   \n",
      "3  57.567115  32.493209  28.472618  3.322520  10.749070  3.431370  19.073743   \n",
      "4  53.631384  34.688642  34.201490  2.134903   5.581491  2.129742  19.643589   \n",
      "\n",
      "     x8::Nh   m1::Drot    m2::Dsh  ...   m4::Rmag     m5::Rs    m6::GFF  \\\n",
      "0  7.483969  26.707543  18.729385  ...  17.220396  23.035840  34.804399   \n",
      "1  3.122326  32.104583  14.001025  ...  18.293615  17.630174  29.305783   \n",
      "2  8.291645  33.910351  14.389001  ...  15.979378  25.248739  50.388922   \n",
      "3  6.024050  29.570535  15.498850  ...  14.070291  22.567654  43.801531   \n",
      "4  4.823686  31.919616  19.671613  ...  16.894075  17.446948  38.941501   \n",
      "\n",
      "      p1::W        p4::GFF  p5::BSP_T  p6::BSP_n  p7::BSP_Mu  p8::MSP_n  \\\n",
      "0  0.658658  126463.385768   0.860282  -0.447577    1.015153   0.598805   \n",
      "1 -1.448138   -6034.137718  -0.918992   0.743497    0.098881   0.977144   \n",
      "2  1.282805   78826.701591   2.918427  -1.015112   -0.413248  -1.099346   \n",
      "3  0.955392  -13743.934211   1.341643  -0.807188    0.111320  -0.923332   \n",
      "4  0.650779   -3976.764288   0.709440  -0.857263   -0.266586  -1.195770   \n",
      "\n",
      "   p9::UWP_Mu  \n",
      "0    0.524473  \n",
      "1   -1.245760  \n",
      "2   -0.417232  \n",
      "3    1.169618  \n",
      "4    0.204383  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Base de datos de 10,000 motores guardada en 'generated_motors.csv'.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 6: Preprocesar los nuevos datos con el mismo escalador usado en entrenamiento\n",
    "# =============================================================================\n",
    "# Definir la ruta del archivo del ensemble (se asume que figure_path ya está definido)\n",
    "ensemble_file = os.path.join(model_path, \"best_model_ensemble.pkl\")\n",
    "# Cargar el modelo ensemble utilizando pickle\n",
    "with open(ensemble_file, \"rb\") as f:\n",
    "    loaded_ensemble = pickle.load(f)\n",
    "print(\"Modelo ensemble cargado correctamente desde:\", ensemble_file)\n",
    "\n",
    "# Obtener las predicciones del ensemble para los datos escalados (por ejemplo, el conjunto completo)\n",
    "preds_ensemble = loaded_ensemble.predict(X_scaled_df)\n",
    "\n",
    "# Convertir las predicciones a la escala original\n",
    "preds_original = scaler_Y.inverse_transform(preds_ensemble)\n",
    "\n",
    "# Combinar las predicciones en un DataFrame\n",
    "df_predictions = pd.DataFrame(preds_ensemble, columns=outputs)\n",
    "print(df_predictions.head())\n",
    "\n",
    "# Combinar las variables de entrada originales y las salidas predichas\n",
    "motors = pd.concat([X_new, df_predictions], axis=1)\n",
    "print(motors.head())\n",
    "motors.to_csv(\"generated_motors.csv\", index=False)\n",
    "print(\"Base de datos de 10,000 motores guardada en 'generated_motors.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fef031f6-d7de-4619-a82f-656af0225502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de motores válidos: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 7: Filtrar motores válidos según constraints definidos\n",
    "# =============================================================================\n",
    "def is_valid_motor(row):\n",
    "    # Ejemplo de constraints (ajustar según lo indicado en el paper)\n",
    "    # Se desea que:\n",
    "    # - p1::W esté entre 0.5 y 0.7\n",
    "    # - p7::BSP_Mu esté entre 85 y 90\n",
    "    # - p9::UWP_Mu esté entre 88 y 92\n",
    "    if (0.15 <= row['p1::W'] <= 1) and (50 <= row['p7::BSP_Mu'] <= 99) and (50 <= row['p9::UWP_Mu'] <= 99):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "motors['Valid'] = motors.apply(is_valid_motor, axis=1)\n",
    "valid_motors = motors[motors['Valid']]\n",
    "print(f\"Número de motores válidos: {len(valid_motors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35dbf1e5-bfb3-40a5-91de-7be4b32094bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de motores en la frontera de Pareto: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 6: Calcular y representar la frontera de Pareto\n",
    "# =============================================================================\n",
    "# Objetivos: minimizar p1::W, maximizar p7::BSP_Mu y p9::UWP_Mu\n",
    "def compute_pareto_front(df, objectives):\n",
    "    is_dominated = np.zeros(len(df), dtype=bool)\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            dominates = True\n",
    "            for obj, sense in objectives.items():\n",
    "                if sense == 'min':\n",
    "                    if df.iloc[j][obj] > df.iloc[i][obj]:\n",
    "                        dominates = False\n",
    "                        break\n",
    "                elif sense == 'max':\n",
    "                    if df.iloc[j][obj] < df.iloc[i][obj]:\n",
    "                        dominates = False\n",
    "                        break\n",
    "            if dominates:\n",
    "                is_dominated[i] = True\n",
    "                break\n",
    "    frontier = df[~is_dominated]\n",
    "    return frontier\n",
    "\n",
    "objectives = {'p1::W': 'min', 'p7::BSP_Mu': 'max', 'p9::UWP_Mu': 'max'}\n",
    "valid_motors_reset = valid_motors.reset_index(drop=True)\n",
    "pareto_motors = compute_pareto_front(valid_motors_reset, objectives)\n",
    "print(f\"Número de motores en la frontera de Pareto: {len(pareto_motors)}\")\n",
    "\n",
    "# Representación 3D de la frontera de Pareto\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(valid_motors['p1::W'], valid_motors['p7::BSP_Mu'], valid_motors['p9::UWP_Mu'], \n",
    "           c='blue', label='Válidos', alpha=0.5)\n",
    "ax.scatter(motors[~motors['Valid']]['p1::W'], motors[~motors['Valid']]['p7::BSP_Mu'], motors[~motors['Valid']]['p9::UWP_Mu'], \n",
    "           c='red', label='No válidos', alpha=0.5)\n",
    "ax.scatter(pareto_motors['p1::W'], pareto_motors['p7::BSP_Mu'], pareto_motors['p9::UWP_Mu'], \n",
    "           c='green', label='Frontera Pareto', s=100, marker='D')\n",
    "ax.set_xlabel('p1::W')\n",
    "ax.set_ylabel('p7::BSP_Mu')\n",
    "ax.set_zlabel('p9::UWP_Mu')\n",
    "ax.legend()\n",
    "plt.title('Frontera de Pareto de diseños de motores')\n",
    "plt.savefig(\"pareto_frontier.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daaf2b-c1db-411f-82c7-4404eb09abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 7: Seleccionar el motor válido óptimo\n",
    "# =============================================================================\n",
    "# Se normalizan los objetivos y se define un score compuesto\n",
    "valid_motors_comp = valid_motors.copy()\n",
    "for col, sense in [('p1::W', 'min'), ('p7::BSP_Mu', 'max'), ('p9::UWP_Mu', 'max')]:\n",
    "    col_min = valid_motors_comp[col].min()\n",
    "    col_max = valid_motors_comp[col].max()\n",
    "    if sense == 'min':\n",
    "        valid_motors_comp[col + '_norm'] = 1 - (valid_motors_comp[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        valid_motors_comp[col + '_norm'] = (valid_motors_comp[col] - col_min) / (col_max - col_min)\n",
    "\n",
    "valid_motors_comp['composite_score'] = (valid_motors_comp['p1::W_norm'] +\n",
    "                                          valid_motors_comp['p7::BSP_Mu_norm'] +\n",
    "                                          valid_motors_comp['p9::UWP_Mu_norm'])\n",
    "optimal_motor = valid_motors_comp.loc[valid_motors_comp['composite_score'].idxmax()]\n",
    "print(\"Motor válido óptimo (según score compuesto):\")\n",
    "print(optimal_motor)\n",
    "\n",
    "optimal_motor.to_frame().T.to_csv(\"optimal_motor.csv\", index=False)\n",
    "print(\"El motor óptimo se ha guardado en 'optimal_motor.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
