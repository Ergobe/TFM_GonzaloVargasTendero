{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe6a29b-9eb9-4744-aa32-544f60294565",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae3baa-03f5-4257-bd0d-b0aad83e2ea2",
   "metadata": {},
   "source": [
    "## 3. Modelo de Optimización y Prognosis (MOP)\n",
    "\n",
    "### 3.1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff92533-1e76-4f8f-9cf7-d0d175ed192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 0: Importar librerías y definir funciones auxiliares\n",
    "# =============================================================================\n",
    "\n",
    "# Librerías necesarias\n",
    "import os\n",
    "import re  # Import the regular expression module\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Preprocesamiento, modelado y métricas\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e4a49d-cf1f-4808-95bb-7162184e43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar nombres de archivo inválidos\n",
    "def clean_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)\n",
    "\n",
    "# Función para calcular la correlación p_ij según la fórmula del paper:\n",
    "#   p_ij = (1/(N-1)) * Σ[(ŷ(k) - μ_ŷ) * (x_j(k) - μ_xj)] / (σ_ŷ σ_xj)\n",
    "def compute_corr(y, x):\n",
    "    N = len(y)\n",
    "    mean_y = np.mean(y)\n",
    "    mean_x = np.mean(x)\n",
    "    std_y = np.std(y, ddof=1)\n",
    "    std_x = np.std(x, ddof=1)\n",
    "    return np.sum((y - mean_y) * (x - mean_x)) / ((N - 1) * std_y * std_x)\n",
    "\n",
    "# Función para dibujar un mapa de calor con seaborn\n",
    "def plot_heatmap(matrix, col_labels, row_labels, title, ax=None):\n",
    "    \"\"\"\n",
    "    Dibuja un mapa de calor de 'matrix' usando seaborn.\n",
    "    'col_labels' y 'row_labels' definen las etiquetas de columnas y filas.\n",
    "    Si se proporciona 'ax', se dibuja en ese subplot; de lo contrario, se crea uno nuevo.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", xticklabels=col_labels,\n",
    "                yticklabels=row_labels, cmap=\"viridis\", ax=ax)\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "# Función para calcular el diccionario de CoP para cada salida y cada modelo\n",
    "def compute_cop_results(metricas, outputs):\n",
    "    \"\"\"\n",
    "    Genera un diccionario de CoP con la estructura:\n",
    "      { output1: { 'PLS': cop_value, 'LR': cop_value, ... },\n",
    "        output2: { 'PLS': cop_value, ... },\n",
    "        ... }\n",
    "    Se asume que 'metricas' tiene, para cada modelo, una lista de valores de CoP\n",
    "    en el mismo orden que 'outputs'.\n",
    "    \"\"\"\n",
    "    cop_results = {}\n",
    "    for j, output in enumerate(outputs):\n",
    "        cop_results[output] = {}\n",
    "        for model_name in metricas.keys():\n",
    "            cop_results[output][model_name] = metricas[model_name]['CoP'][j]\n",
    "    return cop_results\n",
    "\n",
    "# Función para graficar los CoP en subplots y guardar la figura\n",
    "def plot_cop_subplots(cop_results, outputs, figure_path, filename=\"CoP_para_cada_modelo.png\"):\n",
    "    \"\"\"\n",
    "    Dibuja un gráfico de subplots, donde cada subplot es un gráfico de barras con los CoP\n",
    "    de cada modelo para una variable de salida.\n",
    "    La figura se guarda en 'figure_path/filename'.\n",
    "    \"\"\"\n",
    "    n_out = len(outputs)\n",
    "    ncols = 3\n",
    "    nrows = ceil(n_out / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12, 6 * nrows))\n",
    "    axes = axes.flatten() if n_out > 1 else [axes]\n",
    "    \n",
    "    for i, output in enumerate(outputs):\n",
    "        model_names = list(cop_results[output].keys())\n",
    "        cop_vals = [cop_results[output][m] for m in model_names]\n",
    "        ax = axes[i]\n",
    "        ax.bar(model_names, cop_vals, color=\"steelblue\")\n",
    "        ax.set_title(f\"CoP para {output}\", fontsize=14)\n",
    "        ax.set_ylabel(\"CoP\", fontsize=12)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    # Eliminar ejes sobrantes si existen\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    figure_file = os.path.join(figure_path, filename)\n",
    "    plt.savefig(figure_file, dpi=1080)\n",
    "    plt.close()\n",
    "    print(f\"Figura de CoP guardada en: {figure_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b369df5f-7f54-4a94-8e28-e7a51fc84316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de datos: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\DB_MOP\\design_DB_preprocessed_400_Uniforme.csv\n",
      "Ruta de figuras: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Figuras_MOP\\400_MOT_Uniforme\n",
      "C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Modelos_MOP\\400_MOT_Uniforme\n",
      "Ruta de modelos: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Modelos_MOP\\400_MOT_Uniforme\n",
      "Archivo cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 1: Definir rutas, cargar datos y configurar directorios\n",
    "# =============================================================================\n",
    "base_path = os.getcwd()  # Se asume que el notebook se ejecuta desde la carpeta 'MOP'\n",
    "db_path = os.path.join(base_path, \"DB_MOP\")\n",
    "fig_path = os.path.join(base_path, \"Figuras_MOP\")\n",
    "model_path = os.path.join(base_path, \"Modelos_MOP\")\n",
    "\n",
    "# Ruta al archivo de la base de datos\n",
    "data_file = os.path.join(db_path, \"design_DB_preprocessed_400_Uniforme.csv\")\n",
    "print(\"Ruta de datos:\", data_file)\n",
    "\n",
    "# Ruta donde se guardarán las figuras\n",
    "figure_path = os.path.join(fig_path, \"400_MOT_Uniforme\")\n",
    "if not os.path.exists(figure_path):\n",
    "    os.makedirs(figure_path)\n",
    "print(\"Ruta de figuras:\", figure_path)\n",
    "\n",
    "# Ruta al archivo de los modelos\n",
    "model_path = os.path.join(model_path, \"400_MOT_Uniforme\")\n",
    "print(model_path)\n",
    "print(\"Ruta de modelos:\", model_path)\n",
    "\n",
    "# Lectura del archivo CSV\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "    print(\"Archivo cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Archivo no encontrado. Revisa la ruta del archivo.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: Problema al analizar el archivo CSV. Revisa el formato del archivo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "# Función para limpiar nombres de archivo inválidos\n",
    "def clean_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba34d7a-68ea-4aff-9af0-ec390f9e1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 2: Preprocesar datos: separar columnas en X, M, P y convertir a numérico\n",
    "# =============================================================================\n",
    "X_cols = [col for col in df.columns if col.startswith('x')]\n",
    "M_cols = [col for col in df.columns if col.startswith('m')]\n",
    "P_cols = [col for col in df.columns if col.startswith('p')]\n",
    "\n",
    "X = df[X_cols].copy()\n",
    "M = df[M_cols].copy()\n",
    "P = df[P_cols].copy()\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "for col in M.columns:\n",
    "    M[col] = pd.to_numeric(M[col], errors='coerce')\n",
    "for col in P.columns:\n",
    "    P[col] = pd.to_numeric(P[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62821794-548b-465e-98a6-2c35a1fc33a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables de entrada: ['x1::OSD', 'x2::Dint', 'x3::L', 'x4::tm', 'x5::hs2', 'x6::wt', 'x7::Nt', 'x8::Nh', 'm1::Drot', 'm2::Dsh', 'm3::he', 'm4::Rmag', 'm5::Rs', 'm6::GFF']\n",
      "Variables de salida: ['p1::W', 'p4::GFF', 'p5::BSP_T', 'p6::BSP_n', 'p7::BSP_Mu', 'p8::MSP_n', 'p9::UWP_Mu']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 3: Seleccionar variables de entrada y salida\n",
    "# =============================================================================\n",
    "# Las variables de salida se toman de P; se eliminan 'p2::Tnom' y 'p3::nnom' si existen.\n",
    "outputs = [col for col in P.columns]\n",
    "if 'p2::Tnom' in outputs:\n",
    "    outputs.remove('p2::Tnom')\n",
    "if 'p3::nnom' in outputs:\n",
    "    outputs.remove('p3::nnom')\n",
    "\n",
    "# Las variables de entrada se obtienen concatenando X y M.\n",
    "X_M = pd.concat([X, M], axis=1)\n",
    "features = list(X_M.columns)\n",
    "print(\"Variables de entrada:\", features)\n",
    "print(\"Variables de salida:\", outputs)\n",
    "\n",
    "# Redefinir X y Y usando los nombres de columnas seleccionados\n",
    "X = df[features]\n",
    "Y = df[outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c863f8dd-22be-42ac-9241-fa530feee6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 4: Escalado de datos y separación en entrenamiento/test\n",
    "# =============================================================================\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y)\n",
    "\n",
    "# Separar en conjuntos de entrenamiento (80%) y test (20%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = pd.DataFrame(scaler_X.transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled  = pd.DataFrame(scaler_X.transform(X_test), columns=X_test.columns)\n",
    "Y_train_scaled = pd.DataFrame(scaler_Y.transform(Y_train), columns=Y_train.columns)\n",
    "Y_test_scaled  = pd.DataFrame(scaler_Y.transform(Y_test), columns=Y_test.columns)\n",
    "\n",
    "# Crear DataFrames escalados completos (para reentrenamiento final y predicciones)\n",
    "X_scaled_df = pd.DataFrame(scaler_X.transform(X), columns=X.columns, index=X.index)\n",
    "Y_scaled_df = pd.DataFrame(scaler_Y.transform(Y), columns=Y.columns, index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a32dba-7e47-4299-9326-259d0cab5ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número óptimo de componentes para modelar PLS es: 9\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 5: Cálculo de los hiperparámetros para cada modelo\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# Paso 5.1: PLS - Hiperparámetros\n",
    "# =============================================================================\n",
    "\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Para PLS, se determina el número óptimo de componentes mediante validación cruzada\n",
    "mse_pls = []\n",
    "componentes = np.arange(1, min(len(X.columns), 20))\n",
    "for n in componentes:\n",
    "    pls_temp = PLSRegression(n_components=n)\n",
    "    scores = cross_val_score(pls_temp, X_train_scaled, Y_train_scaled, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_pls.append(-scores.mean())\n",
    "n_componentes_optimos = componentes[np.argmin(mse_pls)]\n",
    "print(\"=== Optimización de PLS ===\")\n",
    "print(f'El número óptimo de componentes para modelar PLS es: {n_componentes_optimos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f756fb-d33a-4e99-9704-641fd03ecad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "OrderedDict({'kernel__k1__length_scale': 43.23791495560915, 'kernel__k2__noise_level': 97.3812547621765})\n",
      "Mejor score (neg MSE): -0.06469244596554043\n",
      "MSE en test: 4.920e-02\n",
      "R² en test: 0.950\n",
      "Kernel final optimizado:\n",
      "RBF(length_scale=4.15) + WhiteKernel(noise_level=0.015)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 5.2: Kriging (GPR) - Hiperparámetros\n",
    "# =============================================================================\n",
    "# Instanciar el modelo GPR sin reinicios en el optimizador ya que BayesSearchCV se encargará de buscar\n",
    "kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "         WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-8, 1e+2))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42, n_restarts_optimizer=0)\n",
    "\n",
    "'''\n",
    "# Usamos los parámetros obtenidos en un primer entrenamiento:\n",
    "kernel = RBF(length_scale=1.12, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "         WhiteKernel(noise_level=0.035, noise_level_bounds=(1e-8, 1e+7))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42, n_restarts_optimizer=10)\n",
    "'''\n",
    "\n",
    "# Definir el espacio de búsqueda para los hiperparámetros del kernel.\n",
    "# La notación \"kernel__k1__length_scale\" y \"kernel__k2__noise_level\" es la que usa scikit-learn\n",
    "# para acceder a los parámetros del kernel compuesto (k1 corresponde a RBF y k2 a WhiteKernel).\n",
    "param_space = {\n",
    "    \"kernel__k1__length_scale\": Real(1e-2, 1e3, prior=\"log-uniform\"),\n",
    "    \"kernel__k2__noise_level\": Real(1e-8, 1e+2, prior=\"log-uniform\")\n",
    "}\n",
    "# Configurar la optimización bayesiana con BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=gpr,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,           # número de iteraciones de búsqueda\n",
    "    cv=3,                # validación cruzada de 3 pliegues\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda sobre los datos escalados\n",
    "opt.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"=== Optimización de GPR ===\")\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(opt.best_params_)\n",
    "print(\"Mejor score (neg MSE):\", opt.best_score_)\n",
    "\n",
    "# Suponiendo que 'opt' es tu objeto BayesSearchCV que ha sido ajustado\n",
    "best_gpr = opt.best_estimator_  # Obtenemos el mejor modelo GPR optimizado\n",
    "final_kernel = best_gpr.kernel_\n",
    "\n",
    "# Asumiendo que el kernel es la suma de RBF (k1) y WhiteKernel (k2)\n",
    "final_length_scale = final_kernel.k1.length_scale\n",
    "final_noise_level = final_kernel.k2.noise_level\n",
    "\n",
    "# Evaluar el modelo optimizado en el conjunto de test\n",
    "y_pred = opt.predict(X_test_scaled)\n",
    "mse = mean_squared_error(Y_test_scaled, y_pred)\n",
    "r2 = r2_score(Y_test_scaled, y_pred)\n",
    "print(f\"MSE en test: {mse:.3e}\")\n",
    "print(f\"R² en test: {r2:.3f}\")\n",
    "\n",
    "# Puedes también imprimir el kernel final ajustado:\n",
    "print(\"Kernel final optimizado:\")\n",
    "print(opt.best_estimator_.kernel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f2e92c-a41c-4dc7-9f2f-ba06869267a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimización de LR ===\n",
      "Mejores parámetros: {'fit_intercept': False}\n",
      "Mejor score (neg MSE): -0.18460580009485303\n",
      "Hiperparámetros óptimos de LR: {'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 5.3: Regresión Lineal (LR) - Hiperparámetros\n",
    "# =============================================================================\n",
    "# Para LinearRegression, se optimiza el parámetro \"fit_intercept\"\n",
    "lr_param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "lr_grid = GridSearchCV(LinearRegression(), lr_param_grid, \n",
    "                         cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lr_grid.fit(X_train_scaled, Y_train_scaled)\n",
    "print(\"=== Optimización de LR ===\")\n",
    "print(\"Mejores parámetros:\", lr_grid.best_params_)\n",
    "print(\"Mejor score (neg MSE):\", lr_grid.best_score_)\n",
    "best_lr_params = lr_grid.best_params_  # Ej: {'fit_intercept': True}\n",
    "print(\"Hiperparámetros óptimos de LR:\", best_lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "610734c5-9d63-4323-bbc5-6ee54de11644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimización de SVR ===\n",
      "Mejores parámetros: {'estimator__C': 10, 'estimator__epsilon': 0.01}\n",
      "Mejor score (neg MSE): -0.09212818167779144\n",
      "Hiperparámetros óptimos de SVR (con prefijo): {'estimator__C': 10, 'estimator__epsilon': 0.01}\n",
      "Hiperparámetros óptimos de SVR: {'C': 10, 'epsilon': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 5.4: Support Vector Regression (SVR) - Hiperparámetros\n",
    "# =============================================================================\n",
    "# Usamos MultiOutputRegressor para manejar salidas múltiples.\n",
    "# Se optimizan los parámetros C y epsilon.\n",
    "svr_param_grid = {\n",
    "    'estimator__C': [0.1, 1, 10, 100],\n",
    "    'estimator__epsilon': [0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "svr_grid = GridSearchCV(MultiOutputRegressor(SVR(kernel='rbf')),\n",
    "                        svr_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "svr_grid.fit(X_train_scaled, Y_train_scaled)\n",
    "print(\"=== Optimización de SVR ===\")\n",
    "print(\"Mejores parámetros:\", svr_grid.best_params_)\n",
    "print(\"Mejor score (neg MSE):\", svr_grid.best_score_)\n",
    "\n",
    "best_svr_params = svr_grid.best_params_\n",
    "print(\"Hiperparámetros óptimos de SVR (con prefijo):\", best_svr_params)\n",
    "\n",
    "# El grid de SVR se realizó usando MultiOutputRegressor, por lo que los parámetros tienen el prefijo 'estimator__'.\n",
    "# Extraemos los parámetros y removemos dicho prefijo para pasarlos al estimador SVR.\n",
    "svr_params = {key.replace('estimator__', ''): value for key, value in best_svr_params.items()}\n",
    "print(\"Hiperparámetros óptimos de SVR:\", svr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdd6fca4-0a42-46f0-b558-e8ce6dab1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimización de RF ===\n",
      "Mejores parámetros: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejor score (neg MSE): -0.2355302659522201\n",
      "Hiperparámetros óptimos de RF: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 5.5: Random Forest (RF) - Hiperparámetros\n",
    "# =============================================================================\n",
    "# Se optimizan n_estimators, max_depth y min_samples_split.\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 20]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid,\n",
    "                       cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_scaled, Y_train_scaled)\n",
    "print(\"=== Optimización de RF ===\")\n",
    "print(\"Mejores parámetros:\", rf_grid.best_params_)\n",
    "print(\"Mejor score (neg MSE):\", rf_grid.best_score_)\n",
    "best_rf_params = rf_grid.best_params_\n",
    "print(\"Hiperparámetros óptimos de RF:\", best_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a77520-2022-493c-a8f8-9fa26f82d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 5: Entrenar los modelos subrogados\n",
    "# =============================================================================\n",
    "# --- Modelo PLS (con 9 componentes) ---\n",
    "model_PLS = PLSRegression(n_components=n_componentes_optimos)\n",
    "model_PLS.fit(X_train_scaled, Y_train_scaled)\n",
    "predicciones_test_pls = model_PLS.predict(X_test_scaled)\n",
    "\n",
    "# --- Modelo de Regresión Lineal (LR) ---\n",
    "model_LR = LinearRegression()\n",
    "model_LR.fit(X_train_scaled, Y_train_scaled)\n",
    "predicciones_test_lr = model_LR.predict(X_test_scaled)\n",
    "\n",
    "# --- Modelo KRIGING (GPR) ---\n",
    "'''\n",
    "kernel = RBF(length_scale=3.74, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "         WhiteKernel(noise_level=0.00211, noise_level_bounds=(1e-8, 100))\n",
    "'''\n",
    "kernel = RBF(length_scale=final_length_scale, length_scale_bounds=(1e-2, 1e3)) + \\\n",
    "         WhiteKernel(noise_level=final_noise_level, noise_level_bounds=(1e-8, 100))\n",
    "model_kriging = GaussianProcessRegressor(kernel=kernel, random_state=42, n_restarts_optimizer=10)\n",
    "model_kriging.fit(X_train_scaled, Y_train_scaled)\n",
    "predicciones_test_kriging = model_kriging.predict(X_test_scaled)\n",
    "\n",
    "# --- Modelo Support Vector Regression (SVR) ---\n",
    "model_svr = MultiOutputRegressor(SVR(kernel='rbf', C=1.0, epsilon=0.1))\n",
    "model_svr.fit(X_train_scaled, Y_train_scaled)\n",
    "predicciones_test_svr = model_svr.predict(X_test_scaled)\n",
    "\n",
    "# --- Modelo Random Forest (RF) ---\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train_scaled, Y_train_scaled)\n",
    "predicciones_test_rf = model_rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d6a5872-7ade-422d-b968-22376ccc6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 6: Calcular métricas (MSE, RMSE, MAE, R2, CoP) para cada modelo\n",
    "# =============================================================================\n",
    "# Crear un diccionario que asocie cada modelo con sus predicciones sobre el conjunto de test\n",
    "modelos = {\n",
    "    'PLS': (model_PLS, predicciones_test_pls),\n",
    "    'LR': (model_LR, predicciones_test_lr),\n",
    "    'GPR': (model_kriging, predicciones_test_kriging),\n",
    "    'SVR': (model_svr, predicciones_test_svr),\n",
    "    'RF': (model_rf, predicciones_test_rf)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e20ef8-a2a3-4c6d-a3dd-1d58cc7d8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar diccionario de métricas para cada modelo\n",
    "metricas = {nombre: {} for nombre in modelos.keys()}\n",
    "for nombre, (modelo, preds) in modelos.items():\n",
    "    metricas[nombre]['MSE'] = []\n",
    "    metricas[nombre]['RMSE'] = []\n",
    "    metricas[nombre]['MAE'] = []\n",
    "    metricas[nombre]['R2'] = []\n",
    "    metricas[nombre]['CoP'] = []\n",
    "    # Calcular métricas para cada variable de salida\n",
    "    for i, col in enumerate(Y_test_scaled.columns):\n",
    "        y_true = Y_test_scaled[col].values\n",
    "        y_pred = preds[:, i]\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        N = len(y_true)\n",
    "        mean_y = np.mean(y_true)\n",
    "        mean_y_pred = np.mean(y_pred)\n",
    "        std_y = np.std(y_true, ddof=1)\n",
    "        std_y_pred = np.std(y_pred, ddof=1)\n",
    "        denominador = (N - 1) * std_y * std_y_pred\n",
    "        cop = (np.sum((y_true - mean_y) * (y_pred - mean_y_pred)) / denominador) ** 2 if denominador != 0 else np.nan\n",
    "        metricas[nombre]['MSE'].append(mse)\n",
    "        metricas[nombre]['RMSE'].append(rmse)\n",
    "        metricas[nombre]['MAE'].append(mae)\n",
    "        metricas[nombre]['R2'].append(r2)\n",
    "        metricas[nombre]['CoP'].append(cop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363d3a34-8266-435d-8580-cd3f0e6f5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 6.1: Representar métricas como gráficos de barras (subplot por métrica) para cada variable de salida\n",
    "# =============================================================================\n",
    "\n",
    "# Lista de métricas a representar\n",
    "metric_names = ['CoP', 'R2', 'MSE', 'RMSE', 'MAE']\n",
    "# Lista de modelos, extraída del diccionario 'metricas'\n",
    "models_list = list(metricas.keys())\n",
    "n_models = len(models_list)\n",
    "\n",
    "# Usar una paleta de colores pastel (una por cada modelo)\n",
    "colors = sns.color_palette(\"pastel\", n_models)\n",
    "\n",
    "# Iterar sobre cada variable de salida\n",
    "for i, output in enumerate(outputs):\n",
    "    # Crear una figura para la variable de salida actual\n",
    "    fig, axs = plt.subplots(1, len(metric_names), figsize=(5 * len(metric_names), 4))\n",
    "    \n",
    "    # Asegurar que axs sea iterable (si solo hay un subplot)\n",
    "    if len(metric_names) == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    # Para cada métrica, crear un subplot con barras para cada modelo\n",
    "    for j, metric in enumerate(metric_names):\n",
    "        # Extraer los valores de la métrica 'metric' para el modelo actual y la variable 'output'\n",
    "        values = [metricas[model][metric][i] for model in models_list]\n",
    "        ax = axs[j]\n",
    "        # Crear gráfico de barras: eje x = modelos, eje y = valor de la métrica\n",
    "        ax.bar(models_list, values, color=colors)\n",
    "        # Configurar título y etiquetas del subplot\n",
    "        ax.set_title(f\"{metric}\", fontsize=10)\n",
    "        ax.set_ylabel(metric, fontsize=9)\n",
    "        # Agregar etiquetas de valor sobre cada barra\n",
    "        for k, v in enumerate(values):\n",
    "            ax.text(k, v, f\"{v:.3f}\", ha='center', va='bottom', fontsize=8)\n",
    "        # Ajustar el límite del eje y para mayor claridad\n",
    "        ax.set_ylim(0, max(values) * 1.1)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    # Título general de la figura para la variable de salida\n",
    "    fig.suptitle(f\"Métricas para la variable de salida: {output}\", fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    # Guardar la figura en la carpeta 'figure_path' usando el nombre de la variable de salida\n",
    "    output_file = os.path.join(figure_path, f\"Métricas_{clean_filename(output)}.png\")\n",
    "    plt.savefig(output_file, dpi=1080)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc75b970-48ba-43c6-9ad9-b0b44a8d48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de CoP:\n",
      "                 PLS        LR       GPR       SVR        RF\n",
      "p1::W       0.982915  0.982494  0.988938  0.946328  0.872430\n",
      "p4::GFF     0.991414  0.991814  0.988216  0.953189  0.919211\n",
      "p5::BSP_T   0.904445  0.904293  0.989911  0.936498  0.875497\n",
      "p6::BSP_n   0.884458  0.872802  0.958648  0.872561  0.887538\n",
      "p7::BSP_Mu  0.641967  0.605408  0.956429  0.897200  0.852624\n",
      "p8::MSP_n   0.800683  0.798793  0.915076  0.825968  0.875817\n",
      "p9::UWP_Mu  0.522519  0.498209  0.874946  0.742160  0.585583\n",
      "Figura de CoP guardada en: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Figuras_MOP\\400_MOT_Uniforme\\CoP_para_cada_modelo.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 7: Representar gráficamente los CoP para cada modelo y salida\n",
    "# =============================================================================\n",
    "# Crear un DataFrame donde las filas son las variables de salida y las columnas los modelos\n",
    "cop_df = pd.DataFrame({nombre: metricas[nombre]['CoP'] for nombre in modelos.keys()},\n",
    "                      index=Y_test_scaled.columns)\n",
    "print(\"Valores de CoP:\")\n",
    "print(cop_df)\n",
    "\n",
    "# Graficar los CoP con un gráfico de barras\n",
    "cop_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Coefficient of Prognosis (CoP) por modelo y variable de salida\")\n",
    "plt.ylabel(\"CoP\")\n",
    "plt.xlabel(\"Variable de salida\")\n",
    "plt.legend(title=\"Modelo\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcular el diccionario cop_results para uso en subplots\n",
    "cop_results = compute_cop_results(metricas, Y_test_scaled.columns.tolist())\n",
    "\n",
    "# Graficar los CoP en subplots y guardar la figura\n",
    "plot_cop_subplots(cop_results, Y_test_scaled.columns.tolist(), figure_path, filename=\"CoP_para_cada_modelo.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386b289e-5231-476b-ba32-a42f85d985ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo para cada variable de salida basado en CoP:\n",
      " - p1::W: GPR (CoP = 0.989)\n",
      " - p4::GFF: LR (CoP = 0.992)\n",
      " - p5::BSP_T: GPR (CoP = 0.990)\n",
      " - p6::BSP_n: GPR (CoP = 0.959)\n",
      " - p7::BSP_Mu: GPR (CoP = 0.956)\n",
      " - p8::MSP_n: GPR (CoP = 0.915)\n",
      " - p9::UWP_Mu: GPR (CoP = 0.875)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 8: Seleccionar el mejor modelo (mayor CoP) para cada variable de salida\n",
    "# =============================================================================\n",
    "best_models = {}\n",
    "for salida in cop_df.index:\n",
    "    best_model = cop_df.loc[salida].idxmax()\n",
    "    best_models[salida] = best_model\n",
    "\n",
    "print(\"Mejor modelo para cada variable de salida basado en CoP:\")\n",
    "for output in Y_test_scaled.columns:\n",
    "    bm = best_models.get(output)\n",
    "    if bm is None:\n",
    "        print(f\" - {output}: No se evaluó ningún modelo\")\n",
    "    else:\n",
    "        print(f\" - {output}: {bm} (CoP = {cop_results[output][bm]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b24e9632-a892-4ff7-a39f-fdf2a26cf9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame final:\n",
      "    x1::OSD  x2::Dint     x3::L    x4::tm   x5::hs2    x6::wt    x7::Nt  \\\n",
      "0  1.118507 -0.684970  0.562831 -1.354814  0.697198 -0.842490  0.562394   \n",
      "1 -0.246804  1.317178 -0.167823 -0.586559 -0.444787 -1.375437  1.983416   \n",
      "2 -1.962195 -1.209342  0.085096  0.729742 -0.828538 -0.856794  1.036068   \n",
      "3  1.223531  0.077753  0.619035  1.227435 -0.284446  1.828701  0.088720   \n",
      "4 -0.099770  1.193236 -0.791689  0.283014 -0.415854  0.758933  1.509742   \n",
      "\n",
      "     x8::Nh  m1::Drot   m2::Dsh  ...  m4::Rmag    m5::Rs   m6::GFF     p1::W  \\\n",
      "0 -1.241492 -0.684970 -0.264670  ... -0.612868  0.063445 -1.568586  0.616254   \n",
      "1 -1.241492  1.317178  1.467421  ...  1.353688  0.820624 -0.319066 -0.294723   \n",
      "2 -1.241492 -1.209342 -1.404701  ... -1.253356 -2.054855  1.285226 -0.572744   \n",
      "3 -1.241492  0.077753 -0.292359  ...  0.010649 -0.223213 -0.322286  1.079042   \n",
      "4 -1.241492  1.193236  1.084792  ...  1.181619  0.729811  0.201559 -0.791238   \n",
      "\n",
      "    p4::GFF  p5::BSP_T  p6::BSP_n  p7::BSP_Mu  p8::MSP_n  p9::UWP_Mu  \n",
      "0 -1.647380  -0.308724  -0.771836   -0.678057  -1.010724    0.080188  \n",
      "1  0.071508   0.248358  -0.939474   -1.805028  -1.930897   -1.605852  \n",
      "2  1.309818  -0.452036  -0.693933   -0.672993  -0.789653    0.828801  \n",
      "3 -0.464840  -0.256488  -0.788233    0.282487  -0.795579    1.161948  \n",
      "4  0.318437   0.046181  -0.899498   -0.728928  -1.589624    0.545803  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 9: Crear un DataFrame final combinando X escalado y las predicciones del mejor modelo\n",
    "# =============================================================================\n",
    "# Obtener las predicciones sobre el conjunto completo X_scaled_df para cada modelo\n",
    "predicciones_totales = {\n",
    "    'PLS': model_PLS.predict(X_scaled_df),\n",
    "    'LR': model_LR.predict(X_scaled_df),\n",
    "    'GPR': model_kriging.predict(X_scaled_df),\n",
    "    'SVR': model_svr.predict(X_scaled_df),\n",
    "    'RF': model_rf.predict(X_scaled_df)\n",
    "}\n",
    "\n",
    "# Combinar las predicciones: para cada salida se usa la predicción del modelo con mayor CoP\n",
    "pred_final = np.zeros_like(predicciones_totales['PLS'])\n",
    "for j, salida in enumerate(Y.columns):\n",
    "    modelo_mejor = best_models[salida]\n",
    "    pred_final[:, j] = predicciones_totales[modelo_mejor][:, j]\n",
    "\n",
    "# Crear el DataFrame final con las variables de entrada escaladas y las predicciones\n",
    "final_df = pd.concat([X_scaled_df, pd.DataFrame(pred_final, columns=Y.columns, index=X_scaled_df.index)], axis=1)\n",
    "print(\"Primeras filas del DataFrame final:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9440a60-e7c2-450f-a767-66e0d9d4259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1::OSD</th>\n",
       "      <th>x2::Dint</th>\n",
       "      <th>x3::L</th>\n",
       "      <th>x4::tm</th>\n",
       "      <th>x5::hs2</th>\n",
       "      <th>x6::wt</th>\n",
       "      <th>x7::Nt</th>\n",
       "      <th>x8::Nh</th>\n",
       "      <th>m1::Drot</th>\n",
       "      <th>m2::Dsh</th>\n",
       "      <th>...</th>\n",
       "      <th>m4::Rmag</th>\n",
       "      <th>m5::Rs</th>\n",
       "      <th>m6::GFF</th>\n",
       "      <th>p1::W</th>\n",
       "      <th>p4::GFF</th>\n",
       "      <th>p5::BSP_T</th>\n",
       "      <th>p6::BSP_n</th>\n",
       "      <th>p7::BSP_Mu</th>\n",
       "      <th>p8::MSP_n</th>\n",
       "      <th>p9::UWP_Mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.400</td>\n",
       "      <td>24.05600</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>2.121244</td>\n",
       "      <td>10.249868</td>\n",
       "      <td>2.569301</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.05600</td>\n",
       "      <td>11.940368</td>\n",
       "      <td>...</td>\n",
       "      <td>10.997689</td>\n",
       "      <td>22.277868</td>\n",
       "      <td>22.423594</td>\n",
       "      <td>0.672637</td>\n",
       "      <td>25.007762</td>\n",
       "      <td>0.414321</td>\n",
       "      <td>4870.925974</td>\n",
       "      <td>87.074414</td>\n",
       "      <td>5975.993340</td>\n",
       "      <td>88.769969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.720</td>\n",
       "      <td>32.05280</td>\n",
       "      <td>22.960001</td>\n",
       "      <td>2.456926</td>\n",
       "      <td>7.797124</td>\n",
       "      <td>2.123813</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.05280</td>\n",
       "      <td>16.981005</td>\n",
       "      <td>...</td>\n",
       "      <td>14.912168</td>\n",
       "      <td>23.823524</td>\n",
       "      <td>34.121540</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>43.479524</td>\n",
       "      <td>0.538645</td>\n",
       "      <td>4034.874688</td>\n",
       "      <td>84.023808</td>\n",
       "      <td>4106.740634</td>\n",
       "      <td>83.537379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.840</td>\n",
       "      <td>21.96160</td>\n",
       "      <td>25.120000</td>\n",
       "      <td>3.032072</td>\n",
       "      <td>6.972909</td>\n",
       "      <td>2.557345</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.96160</td>\n",
       "      <td>8.622712</td>\n",
       "      <td>...</td>\n",
       "      <td>9.722782</td>\n",
       "      <td>17.953709</td>\n",
       "      <td>49.140854</td>\n",
       "      <td>0.488521</td>\n",
       "      <td>56.786832</td>\n",
       "      <td>0.382338</td>\n",
       "      <td>5259.442425</td>\n",
       "      <td>87.088123</td>\n",
       "      <td>6425.080130</td>\n",
       "      <td>91.093273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.760</td>\n",
       "      <td>27.10240</td>\n",
       "      <td>29.680002</td>\n",
       "      <td>3.249535</td>\n",
       "      <td>8.141503</td>\n",
       "      <td>4.802138</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.10240</td>\n",
       "      <td>11.859788</td>\n",
       "      <td>...</td>\n",
       "      <td>12.238816</td>\n",
       "      <td>21.692703</td>\n",
       "      <td>34.091393</td>\n",
       "      <td>0.744299</td>\n",
       "      <td>37.715746</td>\n",
       "      <td>0.425979</td>\n",
       "      <td>4789.147800</td>\n",
       "      <td>89.674520</td>\n",
       "      <td>6413.042125</td>\n",
       "      <td>92.127185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.224</td>\n",
       "      <td>31.55776</td>\n",
       "      <td>17.632002</td>\n",
       "      <td>2.836879</td>\n",
       "      <td>7.859266</td>\n",
       "      <td>3.907924</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.55776</td>\n",
       "      <td>15.867500</td>\n",
       "      <td>...</td>\n",
       "      <td>14.569660</td>\n",
       "      <td>23.638145</td>\n",
       "      <td>38.995613</td>\n",
       "      <td>0.454687</td>\n",
       "      <td>46.133107</td>\n",
       "      <td>0.493526</td>\n",
       "      <td>4234.244550</td>\n",
       "      <td>86.936712</td>\n",
       "      <td>4800.008357</td>\n",
       "      <td>90.214995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1::OSD  x2::Dint      x3::L    x4::tm    x5::hs2    x6::wt  x7::Nt  \\\n",
       "0   59.400  24.05600  29.200000  2.121244  10.249868  2.569301    12.0   \n",
       "1   54.720  32.05280  22.960001  2.456926   7.797124  2.123813    18.0   \n",
       "2   48.840  21.96160  25.120000  3.032072   6.972909  2.557345    14.0   \n",
       "3   59.760  27.10240  29.680002  3.249535   8.141503  4.802138    10.0   \n",
       "4   55.224  31.55776  17.632002  2.836879   7.859266  3.907924    16.0   \n",
       "\n",
       "   x8::Nh  m1::Drot    m2::Dsh  ...   m4::Rmag     m5::Rs    m6::GFF  \\\n",
       "0     3.0  23.05600  11.940368  ...  10.997689  22.277868  22.423594   \n",
       "1     3.0  31.05280  16.981005  ...  14.912168  23.823524  34.121540   \n",
       "2     3.0  20.96160   8.622712  ...   9.722782  17.953709  49.140854   \n",
       "3     3.0  26.10240  11.859788  ...  12.238816  21.692703  34.091393   \n",
       "4     3.0  30.55776  15.867500  ...  14.569660  23.638145  38.995613   \n",
       "\n",
       "      p1::W    p4::GFF  p5::BSP_T    p6::BSP_n  p7::BSP_Mu    p8::MSP_n  \\\n",
       "0  0.672637  25.007762   0.414321  4870.925974   87.074414  5975.993340   \n",
       "1  0.531573  43.479524   0.538645  4034.874688   84.023808  4106.740634   \n",
       "2  0.488521  56.786832   0.382338  5259.442425   87.088123  6425.080130   \n",
       "3  0.744299  37.715746   0.425979  4789.147800   89.674520  6413.042125   \n",
       "4  0.454687  46.133107   0.493526  4234.244550   86.936712  4800.008357   \n",
       "\n",
       "   p9::UWP_Mu  \n",
       "0   88.769969  \n",
       "1   83.537379  \n",
       "2   91.093273  \n",
       "3   92.127185  \n",
       "4   90.214995  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   x1::OSD     315 non-null    float64\n",
      " 1   x2::Dint    315 non-null    float64\n",
      " 2   x3::L       315 non-null    float64\n",
      " 3   x4::tm      315 non-null    float64\n",
      " 4   x5::hs2     315 non-null    float64\n",
      " 5   x6::wt      315 non-null    float64\n",
      " 6   x7::Nt      315 non-null    float64\n",
      " 7   x8::Nh      315 non-null    float64\n",
      " 8   m1::Drot    315 non-null    float64\n",
      " 9   m2::Dsh     315 non-null    float64\n",
      " 10  m3::he      315 non-null    float64\n",
      " 11  m4::Rmag    315 non-null    float64\n",
      " 12  m5::Rs      315 non-null    float64\n",
      " 13  m6::GFF     315 non-null    float64\n",
      " 14  p1::W       315 non-null    float64\n",
      " 15  p4::GFF     315 non-null    float64\n",
      " 16  p5::BSP_T   315 non-null    float64\n",
      " 17  p6::BSP_n   315 non-null    float64\n",
      " 18  p7::BSP_Mu  315 non-null    float64\n",
      " 19  p8::MSP_n   315 non-null    float64\n",
      " 20  p9::UWP_Mu  315 non-null    float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 51.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame desescalado guardado en: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Modelos_MOP\\400_MOT_Uniforme\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 9.1: Desescalar el DataFrame final y guardar en CSV\n",
    "# =============================================================================\n",
    "\n",
    "# Separar las columnas de entrada y de salida (recordando que 'features' y 'Y.columns' ya están definidos)\n",
    "X_final_scaled = final_df[features]\n",
    "Y_final_scaled = final_df[Y.columns]\n",
    "\n",
    "# Aplicar el inverso de la transformación para obtener los valores originales (desescalados)\n",
    "X_final_unscaled = pd.DataFrame(scaler_X.inverse_transform(X_final_scaled), \n",
    "                                columns=features, \n",
    "                                index=final_df.index)\n",
    "Y_final_unscaled = pd.DataFrame(scaler_Y.inverse_transform(Y_final_scaled), \n",
    "                                columns=Y.columns, \n",
    "                                index=final_df.index)\n",
    "\n",
    "# Combinar las variables desescaladas en un único DataFrame\n",
    "final_unscaled_df = pd.concat([X_final_unscaled, Y_final_unscaled], axis=1)\n",
    "display(final_unscaled_df.head())\n",
    "display(final_unscaled_df.info())\n",
    "\n",
    "# Definir la ruta de salida para guardar el CSV (puedes ajustar la carpeta y nombre del archivo)\n",
    "output_csv_path = os.path.join(figure_path, \"final_df_desescalado.csv\")\n",
    "\n",
    "# Guardar el DataFrame desescalado en formato CSV\n",
    "model_file = os.path.join(model_path, \"trained_database_optimal.csv\")\n",
    "final_unscaled_df.to_csv(model_file, index=True)\n",
    "print(\"DataFrame desescalado guardado en:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef4d816-36bf-4841-bfcd-32fe7a5b2b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figura de comparación guardada en: C:\\Users\\s00244\\Documents\\GitHub\\MotorDesignDataDriven\\Notebooks\\3.MOP\\Figuras_MOP\\400_MOT_Uniforme\\valores_FEA_vs_valores_predichos.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Paso 10: Graficar comparación (scatter) entre FEA (valores originales escalados)\n",
    "# y las predicciones, usando las métricas calculadas previamente para el mejor modelo\n",
    "# =============================================================================\n",
    "\n",
    "# Lista de variables de salida (asegúrate de que coincide con Y_scaled_df.columns)\n",
    "output_vars = Y_scaled_df.columns.tolist()\n",
    "n_vars = len(output_vars)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_vars / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()  # Asegurarse de tener una lista de ejes\n",
    "\n",
    "# Iterar sobre cada variable de salida\n",
    "for i, col in enumerate(output_vars):\n",
    "    # Extraer valores originales y predichos\n",
    "    y_true = Y_scaled_df[col].values\n",
    "    y_pred = final_df[col].values\n",
    "\n",
    "    # Obtener el mejor modelo para esta variable y extraer las métricas pre-calculadas\n",
    "    best_model = best_models[col]  # best_models ya fue calculado previamente (ej. {'p1::W': 'PLS', ...})\n",
    "    mse  = metricas[best_model]['MSE'][i]\n",
    "    r2   = metricas[best_model]['R2'][i]\n",
    "    cop  = metricas[best_model]['CoP'][i]\n",
    "    \n",
    "    # Dibujar el scatter en el subplot correspondiente (usar ax, no axes)\n",
    "    ax = axes[i]\n",
    "    ax.scatter(y_true, y_pred, alpha=0.6, edgecolor=\"k\")\n",
    "    \n",
    "    # Dibujar la línea de identidad\n",
    "    min_val = min(np.min(y_true), np.min(y_pred))\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    # Configurar etiquetas y título para el subplot\n",
    "    ax.set_title(f\"{col}\")\n",
    "    ax.set_xlabel(\"FEA Simulation (escalado)\")\n",
    "    ax.set_ylabel(\"Prediction (escalado)\")\n",
    "    \n",
    "    # Anotar el subplot con las métricas extraídas para el mejor modelo\n",
    "    annotation = f\"Mejor Modelo: {best_model}\\nCoP: {cop:.3f}\\nR²: {r2:.3f}\\nMSE: {mse:.3f}\"\n",
    "    ax.text(0.05, 0.95, annotation, transform=ax.transAxes, verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Eliminar subplots vacíos si existen\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar la figura en la carpeta 'figure_path'\n",
    "figure_file = os.path.join(figure_path, \"valores_FEA_vs_valores_predichos.png\")\n",
    "plt.savefig(figure_file, dpi=1080)\n",
    "plt.close()\n",
    "print(\"Figura de comparación guardada en:\", figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d61ee9-62d0-4f1c-a4cb-cd56ce99c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Paso 11: Calcular y representar mapas de calor de p₍ᵢⱼ₎ (correlación entre predicción y variables de entrada)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Diccionario con las predicciones de cada modelo en el conjunto de test\n",
    "modelos_pred = {\n",
    "    'PLS': predicciones_test_pls,\n",
    "    'LR': predicciones_test_lr,\n",
    "    'GPR': predicciones_test_kriging,\n",
    "    'SVR': predicciones_test_svr,\n",
    "    'RF': predicciones_test_rf\n",
    "}\n",
    "\n",
    "# Calcular p₍ᵢⱼ₎ para cada modelo\n",
    "p_values_by_model = {}\n",
    "for model_name, preds in modelos_pred.items():\n",
    "    preds = np.asarray(preds)  # Convertir a array de NumPy\n",
    "    # Crear un DataFrame para almacenar p₍ᵢⱼ₎ con índices = salidas, columnas = entradas\n",
    "    p_matrix = pd.DataFrame(index=Y_test_scaled.columns, columns=X_test_scaled.columns, dtype=float)\n",
    "    \n",
    "    # Para cada variable de salida (fila)\n",
    "    for i, out_var in enumerate(Y_test_scaled.columns):\n",
    "        y_pred = preds[:, i]\n",
    "        # Para cada variable de entrada (columna)\n",
    "        for in_var in X_test_scaled.columns:\n",
    "            x_vals = X_test_scaled[in_var].values\n",
    "            # Si x_vals tiene más de una dimensión, tomar la primera columna\n",
    "            if x_vals.ndim > 1:\n",
    "                x_vals = x_vals[:, 0]\n",
    "            # Calcular p₍ᵢⱼ₎ usando la función compute_corr\n",
    "            p_matrix.loc[out_var, in_var] = compute_corr(y_pred, x_vals)\n",
    "    \n",
    "    p_values_by_model[model_name] = p_matrix\n",
    "\n",
    "# Representar mapas de calor de p₍ᵢⱼ₎ para cada modelo y guardarlos\n",
    "for model_name, df_p in p_values_by_model.items():\n",
    "    pij_matrix = df_p.T.values  # Transponer para tener filas = entradas y columnas = salidas\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plot_heatmap(pij_matrix, \n",
    "                 col_labels=Y_test_scaled.columns.tolist(), \n",
    "                 row_labels=X_test_scaled.columns.tolist(),\n",
    "                 title=f\"Mapa de calor de p₍ᵢⱼ₎ para {model_name}\", ax=ax)\n",
    "    plt.tight_layout()\n",
    "    figure_file = os.path.join(figure_path, f\"Mapa_de_calor_pij_{model_name}.png\")\n",
    "    plt.savefig(figure_file, dpi=1080)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec0988d1-4056-4d03-aa95-068e061f2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paso 12: Calcular y representar el mapa de calor de la correlación de Pearson (entradas vs salidas)\n",
    "# =============================================================================\n",
    "# Concatenar X escalado y Y escalado completos\n",
    "combined = pd.concat([X_scaled_df, Y_scaled_df], axis=1)\n",
    "corr_matrix = combined.corr()\n",
    "# Extraer la submatriz: filas = entradas, columnas = salidas\n",
    "pearson_matrix = corr_matrix.loc[X_scaled_df.columns, Y_scaled_df.columns]\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_heatmap(pearson_matrix, col_labels=Y_scaled_df.columns.tolist(),\n",
    "             row_labels=X_scaled_df.columns.tolist(),\n",
    "             title=\"Matriz de correlación de Pearson (entradas vs salidas)\", ax=ax)\n",
    "plt.tight_layout()\n",
    "figure_file = os.path.join(figure_path, \"Mapa_de_calor_Pearson.png\")\n",
    "plt.savefig(figure_file, dpi=1080)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f46dd30-ebf7-4ef3-a944-d263ae4415ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecución completada.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Fin del código\n",
    "# =============================================================================\n",
    "print(\"Ejecución completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11289d-9976-4c82-a070-36ee3b350bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
